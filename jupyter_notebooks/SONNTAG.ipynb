{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reXplan as rx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date as dt_date\n",
    "\n",
    "from pandapower.plotting.plotly import simple_plotly, vlevel_plotly, pf_res_plotly\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from pandapower.plotting.plotly import simple_plotly, vlevel_plotly, pf_res_plotly\n",
    "from utils import * # pplotting functions\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\") # warning are ignored for now\n",
    "simulationName = 'Simbench';\n",
    "network = rx.network.Network(simulationName);\n",
    "simulation = rx.simulation.Sim(simulationName);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ran for 10% - 44 min 40 sec\n",
    "# Ran for 15% - 54 min 51 sec\n",
    "# Ran for 25% - 80 min 14 sec\n",
    "# Ran for 50% - 159 min 49 sec\n",
    "simulation.run_prediction(network, run_type = 'pm_ac_opf', delta = 1e-16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "class NeuNet(object):       # to the class we shall provide a model, a loss_fn and an optimizer.\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        \n",
    "        # We start by storing the arguments as attributes to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)                                                  # here we send the model to the device\n",
    "\n",
    "        # These attributes are defined here, but since they are\n",
    "        # not informed at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None\n",
    "        \n",
    "        # These attributes are going to be computed internally\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.total_epochs = 0\n",
    "\n",
    "        # Creates the train_step function for our model, \n",
    "        # loss function and optimizer\n",
    "        # Note: there are NO ARGS there! It makes use of the class\n",
    "        # attributes directly\n",
    "        self.train_step_fn = self._make_train_step_fn()\n",
    "        # Creates the val_step function for our model and loss\n",
    "        self.val_step_fn = self._make_val_step_fn()\n",
    "\n",
    "    def to(self, device):                                                           # this is the function sending the model to the device\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        try:\n",
    "            self.device = device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            print(f\"Couldn't send it to {device}, sending it to {self.device} instead.\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):                           # data loaders provide the input data in a sutiable format to the model, in a minibatch size\n",
    "        # This method allows the user to define which train_loader (and val_loader, optionally) to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to define a SummaryWriter to interface with TensorBoard\n",
    "        suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')\n",
    "\n",
    "    def _make_train_step_fn(self):\n",
    "        # This method does not need ARGS... it can refer to\n",
    "        # the attributes: self.model, self.loss_fn and self.optimizer\n",
    "        \n",
    "        # Builds function that performs a step in the train loop\n",
    "        def perform_train_step_fn(x, y):\n",
    "            # Sets model to TRAIN mode\n",
    "            self.model.train()                                                      # the model has a different behaviour during training and evaluation mode\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "            # Step 3 - Computes gradients for both \"a\" and \"b\" parameters\n",
    "            loss.backward()\n",
    "            # Step 4 - Updates parameters using gradients and the learning rate\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()                                              # avoid cumulation of gradients\n",
    "\n",
    "            # Returns the loss\n",
    "            return loss.item()\n",
    "\n",
    "        # Returns the function that will be called inside the train loop\n",
    "        return perform_train_step_fn\n",
    "    \n",
    "    def _make_val_step_fn(self):\n",
    "        # Builds function that performs a step in the validation loop\n",
    "        def perform_val_step_fn(x, y):\n",
    "            # Sets model to EVAL mode\n",
    "            self.model.eval()                                                       # here we set the model to evaluation mode\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "            # There is no need to compute Steps 3 and 4, \n",
    "            # since we don't update parameters during evaluation\n",
    "            return loss.item()\n",
    "\n",
    "        return perform_val_step_fn\n",
    "            \n",
    "    def _mini_batch(self, validation=False):\n",
    "        # The mini-batch can be used with both loaders\n",
    "        # The argument `validation`defines which loader and \n",
    "        # corresponding step function is going to be used\n",
    "        if validation:\n",
    "            data_loader = self.val_loader\n",
    "            step_fn = self.val_step_fn\n",
    "        else:\n",
    "            data_loader = self.train_loader\n",
    "            step_fn = self.train_step_fn\n",
    "\n",
    "        if data_loader is None:\n",
    "            return None\n",
    "            \n",
    "        # Once the data loader and step function, this is the \n",
    "        # same mini-batch loop we had before\n",
    "        mini_batch_losses = []\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            x_batch = x_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "\n",
    "            mini_batch_loss = step_fn(x_batch, y_batch)\n",
    "            mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "        loss = np.mean(mini_batch_losses)\n",
    "        return loss\n",
    "\n",
    "    def set_seed(self, seed=42):\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False    \n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    def train(self, n_epochs, seed=42):                                             # this function execute the training of the model\n",
    "        # To ensure reproducibility of the training process\n",
    "        self.set_seed(seed)\n",
    "\n",
    "        for epoch in tqdm(range(n_epochs)):\n",
    "            # Keeps track of the numbers of epochs\n",
    "            # by updating the corresponding attribute\n",
    "            self.total_epochs += 1\n",
    "\n",
    "            # inner loop\n",
    "            # Performs training using mini-batches\n",
    "            loss = self._mini_batch(validation=False)\n",
    "            self.losses.append(loss)\n",
    "\n",
    "            # VALIDATION\n",
    "            # no gradients in validation!\n",
    "            with torch.no_grad():\n",
    "                # Performs evaluation using mini-batches\n",
    "                val_loss = self._mini_batch(validation=True)\n",
    "                self.val_losses.append(val_loss)\n",
    "\n",
    "            # If a SummaryWriter has been set...\n",
    "            if self.writer:                                                         # this is optional, i.e. Tensorboard output\n",
    "                scalars = {'training': loss}\n",
    "                if val_loss is not None:\n",
    "                    scalars.update({'validation': val_loss})\n",
    "                # Records both losses for each epoch under the main tag \"loss\"\n",
    "                self.writer.add_scalars(main_tag='loss',\n",
    "                                        tag_scalar_dict=scalars,\n",
    "                                        global_step=epoch)\n",
    "\n",
    "        if self.writer:\n",
    "            # Closes the writer\n",
    "            self.writer.close()\n",
    "\n",
    "    def save_checkpoint(self, filename):\n",
    "        # Builds dictionary with all elements for resuming training\n",
    "        checkpoint = {'epoch': self.total_epochs,\n",
    "                      'model_state_dict': self.model.state_dict(),\n",
    "                      'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                      'loss': self.losses,\n",
    "                      'val_loss': self.val_losses}\n",
    "\n",
    "        torch.save(checkpoint, filename)\n",
    "\n",
    "    def load_checkpoint(self, filename):\n",
    "        # Loads dictionary\n",
    "        checkpoint = torch.load(filename)\n",
    "\n",
    "        # Restore state for model and optimizer\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        self.total_epochs = checkpoint['epoch']\n",
    "        self.losses = checkpoint['loss']\n",
    "        self.val_losses = checkpoint['val_loss']\n",
    "\n",
    "        self.model.train() # always use TRAIN for resuming training   \n",
    "\n",
    "    def predict(self, x):\n",
    "        # Set is to evaluation mode for predictions\n",
    "        self.model.eval() \n",
    "        # Takes aNumpy input and make it a float tensor\n",
    "        x_tensor = torch.as_tensor(x).float()\n",
    "        # Send input to device and uses model for prediction\n",
    "        y_hat_tensor = self.model(x_tensor.to(self.device))                                 # sending input to device\n",
    "        # Set it back to train mode\n",
    "        self.model.train()\n",
    "        # Detaches it, brings it to CPU and back to Numpy\n",
    "        return y_hat_tensor.detach().cpu().numpy()                                          # sending back to cpu for return\n",
    "\n",
    "    def plot_losses(self):\n",
    "        fig = plt.figure(figsize=(10, 4))\n",
    "        plt.plot(self.losses, label='Training Loss', c='b', lw=1)\n",
    "        plt.plot(self.val_losses, label='Test Loss', c='r', lw=1)\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def add_graph(self):\n",
    "        # Fetches a single mini-batch so we can use add_graph\n",
    "        if self.train_loader and self.writer:\n",
    "            x_sample, y_sample = next(iter(self.train_loader))\n",
    "            self.writer.add_graph(self.model, x_sample.to(self.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reXplan import ml as rxml\n",
    "\n",
    "PATH_MONTECARLO = r\"..\\jupyter_notebooks\\file\\output\\SimBench\\montecarlo_database.csv\" \n",
    "df_montecarlo = pd.read_csv(PATH_MONTECARLO, sep=\",\", index_col=[0, 1, 2, 3, 4])# , decimal=\",\")\n",
    "column_mapping = {col: i+1 for i, col in enumerate(df_montecarlo.columns)}\n",
    "timestep_mapping_df = pd.DataFrame(list(column_mapping.items()), columns=['time', 'timestep'])\n",
    "number_of_iterations = df_montecarlo.index.get_level_values('iteration').max()+1\n",
    "X_df_montecarlo = df_montecarlo.stack().unstack(\"id\")\n",
    "\n",
    "PATH_NETWORK = r\"..\\jupyter_notebooks\\file\\input\\SimBench\\network.xlsx\" \n",
    "df_network = pd.read_excel(PATH_NETWORK, sheet_name=\"profiles\", decimal=\",\")\n",
    "df_network = df_network.drop(index=0).reset_index(drop=True)\n",
    "df_network = df_network.drop(df_network.columns[0], axis=1)\n",
    "#df_network = df_network.drop(df_network.index[-1]) # Testen ob notwendig.\n",
    "df_network= df_network.head(df_montecarlo.shape[1])\n",
    "\n",
    "temp_df = df_network.copy()\n",
    "arr = temp_df.to_numpy()\n",
    "arr = arr.astype(np.float64)\n",
    "df_network = pd.DataFrame(np.tile(arr, (number_of_iterations, 1)), columns = temp_df.columns)\n",
    "\n",
    "df_network.index= X_df_montecarlo.index\n",
    "number_of_lines = len(set(X_df_montecarlo.columns))\n",
    "X_df_montecarlo = pd.concat([X_df_montecarlo, df_network], axis=1)\n",
    "X_df_montecarlo.insert(0, 'idx', range(1, len(X_df_montecarlo) + 1))\n",
    "X = X_df_montecarlo.to_numpy()\n",
    "idx_mapping = X_df_montecarlo.reset_index()\n",
    "idx_mapping.rename(columns={'level_4': 'timestep'}, inplace=True)\n",
    "idx_mapping = idx_mapping[['strata', 'iteration', 'timestep', 'idx']]\n",
    "\n",
    "z = pd.DataFrame(X).iloc[:,1:number_of_lines+1].astype(int).astype(str).agg(''.join, axis=1)\n",
    "l = []\n",
    "from collections import Counter\n",
    "c = Counter(z)\n",
    "for k in z:\n",
    "    if c[k] == 1:\n",
    "        l.append(str('G0'))\n",
    "    else:\n",
    "        l.append(str(k))\n",
    "\n",
    "X_train, X_val = train_test_split(X, train_size = 0.10, test_size = 0.10, stratify = pd.DataFrame(l)[0], shuffle = True, random_state = 42)\n",
    "\n",
    "idx_for_opf = pd.concat([pd.Series(X_train[:, 0]) , pd.Series(X_val[:, 0])])\n",
    "opfs_timesteps = (\n",
    "    X_df_montecarlo[X_df_montecarlo['idx'].isin(idx_for_opf)]\n",
    "    .reset_index()\n",
    "    .rename(columns={'level_4': 'time'})\n",
    "    [['iteration', 'time']]\n",
    "    .merge(timestep_mapping_df, on='time', how='left')\n",
    ")\n",
    "df_opf_list = (\n",
    "    opfs_timesteps.groupby('iteration')['timestep']\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    ")\n",
    "df_opf_list['timestep'] = df_opf_list['timestep'].apply(lambda x: [i - 1 for i in x])\n",
    "\n",
    "PATH_ENGINE = r\"..\\jupyter_notebooks\\file\\output\\SimBench\\engine_database.csv\"\n",
    "df_engine = pd.read_csv(PATH_ENGINE, sep=\",\", index_col=[0, 1, 2, 3, 4])\n",
    "y_df = df_engine.loc[:,:,\"loss_of_load_p_mw\",\"load\",:,:].stack().unstack(\"id\")\n",
    "ysum_df = pd.DataFrame(y_df.sum(axis=1))\n",
    "ysum_df = ysum_df.reset_index()\n",
    "ysum_df.rename(columns={'level_2': 'timestep', 0: 'opf_sum'}, inplace=True)\n",
    "ysum_df = pd.merge(ysum_df, idx_mapping[['strata', 'iteration', 'timestep', 'idx']], \n",
    "                     on=['strata', 'iteration', 'timestep'], \n",
    "                     how='left')\n",
    "Y = ysum_df['opf_sum'].to_numpy().reshape(-1,1)\n",
    "y_train = pd.merge(pd.Series(X_train[:, 0], name='idx'), ysum_df[['idx', 'opf_sum']], on='idx', how='left')['opf_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "idx_for_opf = pd.Series(X_train[:, 0])\n",
    "opfs_timesteps = (\n",
    "    X_df_montecarlo[X_df_montecarlo['idx'].isin(idx_for_opf)]\n",
    "    .reset_index()\n",
    "    .rename(columns={'level_4': 'time'})\n",
    "    [['iteration', 'time']]\n",
    "    .merge(timestep_mapping_df, on='time', how='left')\n",
    ")\n",
    "df_opf_list = (\n",
    "    opfs_timesteps.groupby('iteration')['timestep']\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    ")\n",
    "df_opf_list['timestep'] = df_opf_list['timestep'].apply(lambda x: [i - 1 for i in x])\n",
    "\n",
    "PATH_ENGINE = r\"..\\jupyter_notebooks\\file\\output\\SimBench\\engine_database.csv\"\n",
    "df_engine = pd.read_csv(PATH_ENGINE, sep=\",\", index_col=[0, 1, 2, 3, 4])\n",
    "y_df = df_engine.loc[:,:,\"loss_of_load_p_mw\",\"load\",:,:].stack().unstack(\"id\")\n",
    "ysum_df = pd.DataFrame(y_df.sum(axis=1))\n",
    "ysum_df = ysum_df.reset_index()\n",
    "ysum_df.rename(columns={'level_2': 'timestep', 0: 'opf_sum'}, inplace=True)\n",
    "# ysum_df = pd.merge(ysum_df, idx_mapping[['strata', 'iteration', 'timestep', 'idx']], \n",
    "#                      on=['strata', 'iteration', 'timestep'], \n",
    "#                      how='left')\n",
    "\n",
    "# Y = ysum_df['opf_sum'].to_numpy().reshape(-1,1)\n",
    "# y_train = pd.merge(pd.Series(X_train[:, 0], name='idx'), ysum_df[['idx', 'opf_sum']], on='idx', how='left')['opf_sum']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_for_opf = pd.Series(X_train[:, 0])\n",
    "opfs_timesteps = (\n",
    "    X_df_montecarlo[X_df_montecarlo['idx'].isin(idx_for_opf)]\n",
    "    .reset_index()\n",
    "    .rename(columns={'level_4': 'time'})\n",
    "    [['iteration', 'time']]\n",
    "    .merge(timestep_mapping_df, on='time', how='left')\n",
    ")\n",
    "df_opf_list = (\n",
    "    opfs_timesteps.groupby('iteration')['timestep']\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    ")\n",
    "df_opf_list['timestep'] = df_opf_list['timestep'].apply(lambda x: [i - 1 for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).sort_values(by=0, ascending=True).reset_index(drop=True)[33:36][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
