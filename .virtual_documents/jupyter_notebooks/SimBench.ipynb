


import resiliencyTool as rt
import numpy as np
import pandapower as pp
import pandas as pd
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
from pandapower.plotting.plotly import simple_plotly, vlevel_plotly, pf_res_plotly
from utils import * # pplotting functions
import warnings
warnings.simplefilter("ignore") # warning are ignored for now





simulationName = 'SimBench';
network = rt.network.Network(simulationName);
simulation = rt.simulation.Sim(simulationName);


ref_return_period = 'rp1'
out_db = simulation.initialize_model_rp(network=network,
                               ref_return_period=ref_return_period,
                               iterationNumber=1,
                               maxTotalIteration=20,
                               cv=0.5,
                               x_min=40,
                               x_max=60,
                               ns = 2
                                )


sns.set(rc={'figure.figsize':(11.7,8.27)})
for rp in network.returnPeriods.keys():
    sns.lineplot(x=network.returnPeriods[rp].x_data, y=network.returnPeriods[rp].y_data)


simulation.stratResults


plt.hist(simulation.samples, density=True, bins=20)
for b in np.append(simulation.stratResults["Upper_X1"].values, simulation.stratResults["Lower_X1"].values[0]):
    plt.axvline(x = b, color = 'r')


# Checl Load Flow, compared to PowerFactory results
pp.run.runpp(network.pp_network, enforce_q_lims=True)
network.pp_network.res_ext_grid





timex = rt.simulation.Time(start=5, duration=1)
simulation.run(network, iterationSet = [7], timex = None, run_type = 'pm_ac_opf', delta = 1e-16, saveOutput = True)


pf_res_plotly(network.pp_network);


simulation.results.loc[:,:,:,'network',:]





df = pd.read_csv(rt.config.path.engineDatabaseFile(simulationName), index_col = [0, 1, 2, 3, 4]) # read database with results
df = filter_non_converged_iterations(df) # filterining non-converged iterations
# df = enrich_database(df)
# df_quantiles = get_quantiles_on_iterations(df, [0.05,0.5,0.95]) # reduce data to quantiles


df_line = group_by(df, 'sum', 'iteration', 'field', 'type').loc[:,:,'line']
df_line_quantiles = invert(get_quantiles_on_iterations(df_line, [0.05,0.5,0.95]))
df_line = invert(df_line)





px.line(df_line, x=df_line.index, y = 'in_service', color = 'iteration')








df_load = group_by(filter(df, type = 'load'), 'sum', 'iteration', 'field', 'type')
df_load_quantiles = invert(get_quantiles_on_iterations(df_load, [0.05, 0.25, 0.5, 0.75, 0.95]))
# df_load = invert(df_load) 
# df_load['loss_of_load_p_percentage'] = (df_load['loss_of_load_p_mw'])/df_load['max_p_mw'] *100
df_load_quantiles['loss_of_load_p_percentage'] = (df_load_quantiles['loss_of_load_p_mw'])/df_load_quantiles['max_p_mw'] *100


px.line(df_load_quantiles, x=df_load_quantiles.index, y = 'loss_of_load_p_percentage', color = 'quantile')


df_network = invert(filter(df, type = 'network')) # filter network fields and invert for plotting
px.scatter(df_network, x=df_network.index, y= 'energy_not_served_mwh' )


# fig = make_subplots()
# fig.add_trace(go.Histogram(x = df_network['energy_not_served_mwh']))
# # fig.add_trace(go.Histogram(x = df_network['energy_not_served_mwh']))
# # fig.add_trace(go.Histogram(x = df_network['energy_not_served_mwh'], histnorm='probability', cumulative_enabled = True, name = 'cumulated histogram'), secondary_y = True)
# fig.update_traces(opacity=0.6)
# fig.update_layout(
#     # legend_title= legend_title,
#     barmode='overlay',
#     # height=225,
#     # margin={'l': 20, 'b': 30, 'r': 10, 't': 30},
#     # xaxis_title_text='Value',
#     legend=dict(title = 'energy not served MWh', orientation="h", yanchor="top", y=1.1, xanchor="left", x=0),
#     # template='plotly_dark'
# )
# fig.update_xaxes(showgrid=True, title_text = 'energy not served MWh')
# fig.update_yaxes(showgrid=True,  title_text = 'count')





df_network_condensed = filter(df, type = 'network').sum(axis = 1) # sum over timesteps


df_network_condensed_ = invert(df_network_condensed)
px.histogram(df_network_condensed_, x='energy_not_served_mwh', histnorm='probability')


statistics= df_network_condensed.groupby('field').mean() # average over iterations
EENS = statistics['energy_not_served_mwh']
LOLE = statistics['loss_of_load_p_duration_h']
print(f'EENS : {EENS.round(2)} MWh, LOLE : {LOLE.round(2)} h')








crt_loss_of_load = 30 
df_loss_of_load = df.loc[:,:,"loss_of_load_p_percentage","network"]
Survivability = pd.DataFrame(1 - (df_loss_of_load > crt_loss_of_load).sum() / df_loss_of_load.index.levels[0].size, columns = ['base case'])





df_aux = pd.read_csv(rt.config.path.engineDatabaseFile('basic_example_v1'), index_col = [0, 1, 2, 3])
df_loss_of_load_aux = df_aux.loc[:,"loss_of_load_p_percentage","network"]
Survivability['line 10 reinforced'] = 1 - (df_loss_of_load_aux > crt_loss_of_load).sum() / df_loss_of_load_aux.index.levels[0].size
df_aux = pd.read_csv(rt.config.path.engineDatabaseFile('basic_example_v2'), index_col = [0, 1, 2, 3])
df_loss_of_load_aux = df_aux.loc[:,"loss_of_load_p_percentage","network"]
Survivability['line 2 reparing time improved'] = 1 - (df_loss_of_load_aux > crt_loss_of_load).sum() / df_loss_of_load_aux.index.levels[0].size


px.line(Survivability).update_layout(xaxis_title="time", yaxis_title="Survivability")





df_line = group_by(filter(df, type = 'line'), 'mean', 'iteration', 'field','id') # mean in this case does not have any effect as the groupying levels are the initial ones
df_line = invert(df_line)
# df_line = df_line.loc[df_line.index > '2022-01-01 12:00:00']


fig = go.Figure() # --> put in a function (?)

ids = df_line['id'].drop_duplicates().to_list()

for id in ids:
    fig.add_trace(go.Violin(x=df_line['id'][df_line['id'] == id],
                            y=df_line['loading_percent'][df_line['id'] == id],
                            name=id,
                            box_visible=False,
                            meanline_visible=True,
                            side='positive',
                            orientation = 'v'
                           )
                 
                 )
fig.update_layout(width=1000, height=500)
fig.show()


# fig = go.Figure()

# ids = df_load['id'].drop_duplicates().to_list()

# for id in ids:
#     fig.add_trace(go.Violin(x=df_load['id'][df_load['id'] == id],
#                             y=df_load['loss_of_load_p_percentage'][df_load['id'] == id],
#                             name=id,
#                             box_visible=False,
#                             meanline_visible=True,
#                             side='positive'
#                            )
                 
#                  )
# fig.update_layout(height=500)
# fig.show()


df_bus =invert(filter(df, type = 'bus'))


fig = go.Figure()

ids = df_bus['id'].drop_duplicates().to_list()

for id in ids:
    fig.add_trace(go.Violin(x=df_bus['id'][df_bus['id'] == id],
                            y=df_bus['vm_pu'][df_bus['id'] == id],
                            name=id,
                            #box_visible=True,
                            meanline_visible=True,
                            side='positive',
                            orientation = 'v'
                           )     
                 )
fig.update_layout(width=1000, height = 500)
fig.show()






